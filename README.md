AI-Assisted Hermeneutics: Validating a Large Language Model for the Rhetorical Analysis of the Book of Revelation
================================================================================

This repository contains the full dataset, source code, and analytical notebooks for the article, "AI-Assisted Hermeneutics: Validating a Large Language Model for the Rhetorical Analysis of the Book of Revelation." The project presents a methodologically robust, AI-assisted rhetorical reading of the Apocalypse of John, quantifying the interplay of its dominant theological themes using a bespoke eight-vector lexicon. 

The study establishes its validity through strong alignment with expert human annotation and offers a reproducible, validated heuristic for the large-scale rhetorical mapping of sacred texts.


Repository Structure
--------------------

The project is organized into a clear workflow, separating source data, processing code, and final outputs.

```bash
.
├── LICENSE.txt
├── README.md
├── requirements.txt
│
├── data/
│   ├── input/                       # Raw source files for the pipeline.
│   │   ├── sblgnt_bible.xml         # SBLGNT source text.
│   │   ├── nrsv_bible.xml           # NRSV source text for comparative analysis.
│   │   ├── osborne_structure.txt    # Defines the 30-unit segmentation.
│   │   ├── aune_structure.txt       # Defines the 29-unit segmentation for robustness check.
│   │   └── lemmatized_greek_text.txt # Lemmatized text for proxy validation.
│   │
│   ├── processed/                   # Intermediate files generated by the notebooks.
│   │   ├── osborne_greek_structured.json
│   │   ├── osborne_nrsv_structured.json
│   │   ├── aune_greek_structured.json
│   │   ├── osborne_greek_structured_lemmatized.json
│   │   ├── human_annotations_expert_a.json
│   │   ├── human_annotations_expert_b.json
│   │   └── human_annotations_expert_c.json
│   │
│   └── results/                     # Final, aggregated vector data and metrics.
│       ├── gemini_osborne_greek.json             # Primary results: Gemini on Greek. (By Notebook 01)
│       ├── gemini_osborne_nrsv.json              # Comparative results: Gemini on NRSV. (By Notebook 01)
│       ├── gemini_aune_greek.json                # Robustness check data: Gemini on Aune. (By Notebook 02)
│       ├── groq_osborne_greek.json               # Cross-model validation data: Llama on Greek. (By Notebook 03)
│       ├── validation_metrics.json               # Core validation metrics (stability, cross-model). (By Notebook 03)
│       ├── unstable_case_log.json                # Log of unstable Llama units. (By Notebook 03)
│       ├── human_ai_validation_metrics.json      # Human-AI correlation metrics. (By Notebook 05)
│       ├── human_expert_agreement_metrics.json   # Inter-rater reliability metrics. (By Notebook 05)
│       ├── conceptual_integrity_metrics.json     # Noise simulation test results. (By Notebook 03)
│       └── headline_divergences.json             # Key translation drift results. (By Notebook 04)
│
├── notebooks/                       # Jupyter notebooks for executing the analysis.
│   ├── 01_generate_rhetorical_vectors.ipynb
│   ├── 02_different_structures_check.ipynb
│   ├── 03_LLM_models_check.ipynb
│   ├── 04_different_translations_check.ipynb
│   └── 05_human_ai_validation.ipynb
│
├── src/                             # Helper Python modules imported by the notebooks.
│   ├── corpus_parser.py
│   ├── llm_analyzer.py
│   ├── analysis_utils.py
│   └── config.py
│
└── figures/                         # Publication-ready figures.
    ├── heatmap_osborne_greek.jpg             # (By Notebook 01)
    ├── streamgraph_comparison.jpg            # (By Notebook 02)
    ├── robustness_delta_heatmap.jpg          # (By Notebook 02)
    └── delta_heatmap_greek_vs_nrsv.jpg       # (By Notebook 04)
```

How to Reproduce the Analysis
-----------------------------

1. Set up Environment: Create and activate a Python 3.11 environment.

   ```bash
   conda create -n rev_ai python=3.11 && conda activate rev_ai
   ```

2. Install Dependencies: Install all required packages.
   ```bash
   pip install -r requirements.txt
   ```

4. Configure API Keys: Create a .env file in the project's root directory and add your API keys. This file is ignored by git.
   ```bash
   GOOGLE_API_KEY="your_gemini_api_key_here"
   GROQ_API_KEY="your_groq_api_key_here"
   ```
5. Execute Notebooks: Run the Jupyter notebooks in numerical order (01 through 05). They are designed to be executed sequentially, with each notebook performing a distinct stage of the analysis and generating the necessary files for the next stage.


Notebooks Overview
------------------

The analysis is performed by a sequence of five Jupyter notebooks.

* 01_generate_rhetorical_vectors.ipynb: The main data generation pipeline. It parses input texts (sblgnt_bible.xml, osborne_structure.txt), segments them into narrative units, and calls the configured LLM API to generate the rhetorical vector scores. Its primary output is data/results/gemini_osborne_greek.json.

* 02_different_structures_check.ipynb: Performs the robustness check described in Appendix A. It compares the rhetorical profiles generated using Grant R. Osborne's structure against David E. Aune's structure, producing the comparison metrics and figures (streamgraph_comparison.jpg, robustness_delta_heatmap.jpg).

* 03_LLM_models_check.ipynb: Conducts a suite of validation tests, including intra-model stability, cross-model replication (Gemini vs. Llama), morphological proxy validation, and a conceptual integrity test using noise injection. It outputs key metrics to data/results/validation_metrics.json and other validation files.

* 04_different_translations_check.ipynb: Performs the comparative analysis of the Greek (SBLGNT) vs. English (NRSV) texts to quantify translation drift. It generates the delta_heatmap_greek_vs_nrsv.jpg figure and the headline_divergences.json data file.

* 05_human_ai_validation.ipynb: Calculates and validates the AI's performance against human expert annotations. It computes inter-rater reliability (Fleiss' Kappa) for the human experts and the Pearson correlation between the AI and averaged human scores, saving the results to human_expert_agreement_metrics.json and human_ai_validation_metrics.json.


Citation
--------

If you use the code or data from this repository in your research, please cite the following:

   Agnieszka B. Ziemińska, “AI Rhetoric in Revelation: Dataset & Code,” Zenodo, 2025, DOI: 10.5281/zenodo.16616355


License
-------

* Code (/src, /notebooks): Licensed under the MIT License. See LICENSE.txt for details.

* Generated Data & Figures: Licensed under CC-BY 4.0 (Creative Commons Attribution 4.0). See LICENSE.txt for details.

* Source Texts: The SBLGNT is in the public domain. NRSV excerpts are used under the doctrine of fair dealing for research and critique. The licenses for this project do not grant any rights to reuse the NRSV text.
