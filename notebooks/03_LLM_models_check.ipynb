{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "editable": true,
    "id": "ukzDAffVnQ4h",
    "outputId": "2fb1b65b-2b1b-4196-b982-80d825ccd5e2",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agnie\\AppData\\Local\\Temp\\ipykernel_6128\\1493380328.py:11: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean pair-wise cosine (Gemini-Pro): 0.987\n",
      "Spearman ρ (Gemini vs Llama): 0.529  (p = 1.021e-18)\n",
      "\n",
      "--- Representative Unstable-Case Log (Llama Model) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit (Osborne)</th>\n",
       "      <th>Verse Range</th>\n",
       "      <th>Highest-Variance Vector (Llama)</th>\n",
       "      <th>σ (pp)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unit_020</td>\n",
       "      <td>RE 16:1-21</td>\n",
       "      <td>Judicial Wrath &amp; Punitive Action</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unit (Osborne) Verse Range   Highest-Variance Vector (Llama)  σ (pp)\n",
       "0       unit_020  RE 16:1-21  Judicial Wrath & Punitive Action    4.22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Lemma proxy vs. Categories (Pearson r) ---\n",
      "'Worship & Praise': r = 0.623  (p = 0.0002371)\n",
      "'Judicial Wrath & Punitive Action': r = -0.327  (p = 0.0776)\n",
      "'Lament, Persecution & Endurance': r = 0.026  (p = 0.8899)\n",
      "'Victory, Consolation & New-Creation Hope': r = 0.147  (p = 0.4394)\n",
      "'Cosmic Warfare & Deception': r = -0.247  (p = 0.1889)\n",
      "'Prophetic Exhortation & Warning': r = -0.164  (p = 0.387)\n",
      "'Theophanic Awe & Terror': r = -0.071  (p = 0.7085)\n",
      "'Other/Neutral Content': r = 0.294  (p = 0.1144)\n",
      "\n",
      "──────────────────────────────────────────────────\n",
      "4️⃣  Saving Outputs\n",
      "──────────────────────────────────────────────────\n",
      "✅ Validation metrics saved to '../data/resultsvalidation_metrics.json'\n",
      "✅ Unstable case log saved to '../data/resultsunstable_case_log.json'\n"
     ]
    }
   ],
   "source": [
    "#@title 03 model validation gemini vs llama\n",
    "# ╔═══════════════════════════════════════════════════════════╗\n",
    "# ║ Notebook 03: Model Validation and Analysis                ║\n",
    "# ╚═══════════════════════════════════════════════════════════╝\n",
    "# This notebook validates the LLM outputs by checking intra-model stability,\n",
    "# cross-model replication, and correlation with a morphological proxy.\n",
    "# It also identifies unstable units from the Mistral model.\n",
    "\n",
    "# --- 1️⃣  Setup and Imports ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import re\n",
    "import json\n",
    "import itertools\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Import helper functions from the src directory\n",
    "# Make sure the src directory is in the Python path\n",
    "sys.path.append('../')\n",
    "from src.corpus_parser import load_json, strip_accents\n",
    "from src.analysis_utils import build_runs_df, normalise_uid, mean_pairwise_cos\n",
    "from src.config import * \n",
    "CATEGORIES = ANALYTICAL_CONCEPTS_LIST \n",
    "\n",
    "GEMINI_JSON = 'gemini_osborne_greek.json'\n",
    "MISTRAL_JSON = 'groq_osborne_greek.json'\n",
    "OSBORNE_GREEK_STRUCTURED = 'osborne_greek_structured.json'\n",
    "\n",
    "gem_runs = build_runs_df(load_json(Path(PATH_RESULTS) / GEMINI_JSON))\n",
    "mis_runs = build_runs_df(load_json(Path(PATH_RESULTS) / MISTRAL_JSON))\n",
    "\n",
    "gem_runs[\"unit\"] = gem_runs[\"unit\"].map(normalise_uid)\n",
    "mis_runs[\"unit\"] = mis_runs[\"unit\"].map(normalise_uid)\n",
    "\n",
    "# --- 3️⃣  Perform Validation Analyses ---\n",
    "# Intra-model stability (Gemini)\n",
    "intra_cos = mean_pairwise_cos(gem_runs, CATEGORIES)\n",
    "print(f\"Mean pair-wise cosine (Gemini-Pro): {intra_cos:.3f}\")\n",
    "\n",
    "# Cross-model replication (Gemini vs. Mistral)\n",
    "gem_mean = gem_runs.groupby(\"unit\")[CATEGORIES].mean().sort_index()\n",
    "mis_mean = mis_runs.groupby(\"unit\")[CATEGORIES].mean().sort_index()\n",
    "rho, p = spearmanr(gem_mean.to_numpy().flatten(), mis_mean.to_numpy().flatten())\n",
    "print(f\"Spearman ρ (Gemini vs Llama): {rho:.3f}  (p = {p:.4g})\")\n",
    "\n",
    "# Model-Specific Instability (Llama)\n",
    "mistral_std = mis_runs.groupby(\"unit\")[CATEGORIES].std()\n",
    "verse_range_map = gem_runs.drop_duplicates(subset='unit').set_index('unit')['verse_range']\n",
    "unstable_log = []\n",
    "for unit_id, row in mistral_std.iterrows():\n",
    "    if row.max() >= 3.0:\n",
    "        unstable_log.append({\n",
    "            \"Unit (Osborne)\": unit_id,\n",
    "            \"Verse Range\": verse_range_map.get(unit_id, \"N/A\"),\n",
    "            \"Highest-Variance Vector (Llama)\": row.idxmax(),\n",
    "            \"σ (pp)\": round(row.max(), 2)\n",
    "        })\n",
    "df_unstable = pd.DataFrame(unstable_log).sort_values(by=\"σ (pp)\", ascending=False).reset_index(drop=True)\n",
    "print(\"\\n--- Representative Unstable-Case Log (Llama Model) ---\")\n",
    "display(df_unstable)\n",
    "\n",
    "# Lemma-frequency proxy\n",
    "structured_data = load_json(Path(PATH_PROCESSED) / OSBORNE_GREEK_STRUCTURED)\n",
    "greek_texts = {unit[\"unit_id\"]: unit.get(\"full_text\", \"\") for unit in structured_data[\"narrative_units\"]}\n",
    "target_lemmas = {\"αξιος\", \"προσκυνεω\", \"ευλογια\", \"δοξα\", \"τιμη\", \"κρατος\"}\n",
    "lemma_counts = {normalise_uid(uid): sum(strip_accents(t.lower()) in target_lemmas for t in re.findall(r\"[\\u0370-\\u03FF\\u1F00-\\u1FFF]+\", txt)) for uid, txt in greek_texts.items()}\n",
    "lemma_df = pd.DataFrame(lemma_counts.items(), columns=[\"unit\", \"lemma_count\"])\n",
    "merged = gem_mean.reset_index().merge(lemma_df, on=\"unit\", how=\"inner\")\n",
    "\n",
    "print(\"\\n--- Lemma proxy vs. Categories (Pearson r) ---\")\n",
    "lemma_correlations = {}\n",
    "for category in CATEGORIES:\n",
    "    r, p_l = pearsonr(merged[\"lemma_count\"], merged[category])\n",
    "    print(f\"'{category}': r = {r:.3f}  (p = {p_l:.4g})\")\n",
    "    lemma_correlations[category] = {\"r\": r, \"p_value\": p_l}\n",
    "\n",
    "\n",
    "# --- 4️⃣  Save Outputs ---\n",
    "# This final section saves the key numerical results to structured files,\n",
    "# ensuring the paper's findings are fully reproducible and verifiable.\n",
    "\n",
    "print(\"\\n\" + \"─\" * 50)\n",
    "print(\"4️⃣  Saving Outputs\")\n",
    "print(\"─\" * 50)\n",
    "\n",
    "# Create a dictionary of the core validation metrics\n",
    "validation_metrics = {\n",
    "    \"intra_model_stability\": {\n",
    "        \"model\": \"Gemini\",\n",
    "        \"metric\": \"Mean Pair-wise Cosine Similarity\",\n",
    "        \"value\": intra_cos\n",
    "    },\n",
    "    \"cross_model_replication\": {\n",
    "        \"models\": \"Gemini vs. Llama\",\n",
    "        \"metric\": \"Spearman Correlation (rho)\",\n",
    "        \"value\": rho,\n",
    "        \"p_value\": p\n",
    "    },\n",
    "    \"morphological_proxy\": {\n",
    "        \"model\": \"Gemini\",\n",
    "        \"metric\": \"Pearson Correlation (r)\",\n",
    "        \"proxy\": \"Cultic Lemma Count\",\n",
    "        \"correlations_by_category\": lemma_correlations\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the validation metrics using the PATH_RESULTS variable\n",
    "try:\n",
    "    with open(PATH_RESULTS + 'validation_metrics.json', 'w') as f:\n",
    "        json.dump(validation_metrics, f, indent=4)\n",
    "    print(f\"✅ Validation metrics saved to '{PATH_RESULTS}validation_metrics.json'\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error saving validation metrics: {e}\")\n",
    "\n",
    "# Save the unstable case log using the PATH_RESULTS variable\n",
    "try:\n",
    "    df_unstable.to_json(PATH_RESULTS + 'unstable_case_log.json', orient='records', indent=4)\n",
    "    print(f\"✅ Unstable case log saved to '{PATH_RESULTS}unstable_case_log.json'\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error saving unstable case log: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7YTEI0_L_GnG",
    "outputId": "0f16bba4-a815-4ea3-c535-f8f2c981a10d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating structured lemmatized file at '..\\data\\processed\\osborne_greek_structured_lemmatized.json'...\n",
      "✅ Successfully created '..\\data\\processed\\osborne_greek_structured_lemmatized.json'\n",
      "\n",
      "──────────────────────────────────────────────────\n",
      "4️⃣  Loading LLM Data and Performing Validation\n",
      "──────────────────────────────────────────────────\n",
      "Intra-Model Stability (Gemini): Mean Pair-wise Cosine = 0.987\n",
      "Intra-Model Stability (Groq/Llama): Mean Pair-wise Cosine = 1.000\n",
      "Cross-Model Replication: Spearman ρ (Gemini vs. Groq/Llama) = 0.529 (p = 1.021e-18)\n",
      "\n",
      "--- Representative Unstable-Case Log (Groq/Llama Model) ---\n",
      "  Unit (Osborne) Verse Range Highest-Variance Vector (Groq/Llama)  σ (pp)\n",
      "0       unit_020  RE 16:1-21     Judicial Wrath & Punitive Action    4.22\n",
      "\n",
      "--- Morphological Proxy Validation ---\n",
      "\n",
      "--- Lemma Proxy vs. All Rhetorical Vectors (Pearson r) ---\n",
      "'Worship & Praise': r = 0.717  (p = 8.327e-06)\n",
      "'Judicial Wrath & Punitive Action': r = -0.275  (p = 0.142)\n",
      "'Lament, Persecution & Endurance': r = -0.069  (p = 0.7163)\n",
      "'Victory, Consolation & New-Creation Hope': r = 0.056  (p = 0.7675)\n",
      "'Cosmic Warfare & Deception': r = -0.172  (p = 0.3647)\n",
      "'Prophetic Exhortation & Warning': r = -0.135  (p = 0.4759)\n",
      "'Theophanic Awe & Terror': r = -0.114  (p = 0.5503)\n",
      "'Other/Neutral Content': r = 0.159  (p = 0.4013)\n",
      "\n",
      "──────────────────────────────────────────────────\n",
      "5️⃣  Saving Final Outputs\n",
      "──────────────────────────────────────────────────\n",
      "✅ Validation metrics saved to '..\\data\\results\\validation_metrics.json'\n",
      "✅ Unstable case log saved to '..\\data\\results\\unstable_case_log.json'\n"
     ]
    }
   ],
   "source": [
    "# @title with lemma\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# ║ Notebook 03: Model Validation and Cross-Model Comparison             ║\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "# This notebook performs a complete, end-to-end validation.\n",
    "# 1. It first pre-processes raw structure and lemmatized text files to create\n",
    "#    a structured, lemmatized JSON corpus.\n",
    "# 2. It then uses this corpus and the LLM output files to conduct all validation checks:\n",
    "#    - Intra-model stability (for both Gemini and Groq/Llama)\n",
    "#    - Cross-model replication (Gemini vs. Groq/Llama)\n",
    "#    - Morphological proxy correlation against all vectors\n",
    "#    - Identification of unstable units from the Groq/Llama model.\n",
    "\n",
    "# --- 1️⃣ Setup and Imports ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Ensure helper functions can be imported\n",
    "sys.path.append('../')\n",
    "from src.corpus_parser import load_json\n",
    "from src.analysis_utils import build_runs_df, normalise_uid, mean_pairwise_cos\n",
    "from src.config import * \n",
    "CATEGORIES = ANALYTICAL_CONCEPTS_LIST \n",
    "\n",
    "# Input files for pre-processing\n",
    "LEMMATIZED_GREEK_PATH = Path(PATH_INPUT) / 'lemmatized_greek_text.txt'\n",
    "OSBORNE_STRUCTURE_PATH = Path(PATH_INPUT) / 'osborne_structure.txt'\n",
    "\n",
    "# Intermediate file to be created by this script\n",
    "STRUCTURED_LEMMATIZED_PATH = Path(PATH_PROCESSED) / 'osborne_greek_structured_lemmatized.json'\n",
    "\n",
    "# Input files for LLM analysis\n",
    "GEMINI_JSON_PATH = Path(PATH_RESULTS) / 'gemini_osborne_greek.json'\n",
    "GROQ_JSON_PATH = Path(PATH_RESULTS) / 'groq_osborne_greek.json'\n",
    "\n",
    "# --- 3️⃣ Helper Functions for Pre-processing ---\n",
    "\n",
    "def parse_verse_range(range_str: str) -> tuple[int, int, int, int]:\n",
    "    \"\"\"Parses a verse range string like 'RE 1:1-8' into a tuple.\"\"\"\n",
    "    range_str = range_str.replace('RE ', '').strip()\n",
    "    parts = range_str.split(':')\n",
    "    chap = int(parts[0])\n",
    "    if '-' in parts[1]:\n",
    "        start_v, end_v = map(int, parts[1].split('-'))\n",
    "        return chap, start_v, chap, end_v\n",
    "    else:\n",
    "        verse = int(parts[1])\n",
    "        return chap, verse, chap, verse\n",
    "\n",
    "def load_lemmatized_data(filepath: Path) -> dict:\n",
    "    \"\"\"Loads the lemmatized file into a dictionary keyed by (chapter, verse).\"\"\"\n",
    "    lemmas_by_verse = {}\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 2: continue\n",
    "            ref_str, lemma = parts[0], parts[-1]\n",
    "            chapter, verse = int(ref_str[2:4]), int(ref_str[4:6])\n",
    "\n",
    "            verse_key = (chapter, verse)\n",
    "            if verse_key not in lemmas_by_verse:\n",
    "                lemmas_by_verse[verse_key] = []\n",
    "            lemmas_by_verse[verse_key].append(lemma)\n",
    "    return lemmas_by_verse\n",
    "\n",
    "def create_structured_lemmatized_file(structure_path: Path, lemmatized_text_path: Path, output_path: Path):\n",
    "    \"\"\"\n",
    "    Parses structure and lemmatized text to create a single structured JSON file\n",
    "    where the text for each unit is a string of its lemmas.\n",
    "    \"\"\"\n",
    "    print(f\"Creating structured lemmatized file at '{output_path}'...\")\n",
    "\n",
    "    lemmas_by_verse = load_lemmatized_data(lemmatized_text_path)\n",
    "\n",
    "    narrative_units = []\n",
    "    with open(structure_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if not row or row[0].startswith('#'):\n",
    "                continue\n",
    "            uid, title, range_str = row\n",
    "\n",
    "            start_chap, start_verse, end_chap, end_verse = parse_verse_range(range_str)\n",
    "\n",
    "            unit_lemmas = []\n",
    "            for verse_num in range(start_verse, end_verse + 1):\n",
    "                verse_key = (start_chap, verse_num)\n",
    "                if verse_key in lemmas_by_verse:\n",
    "                    unit_lemmas.extend(lemmas_by_verse[verse_key])\n",
    "\n",
    "            narrative_units.append({\n",
    "                \"unit_id\": uid,\n",
    "                \"title\": title,\n",
    "                \"verse_range\": range_str,\n",
    "                \"lemmatized_text\": \" \".join(unit_lemmas)\n",
    "            })\n",
    "\n",
    "    final_json_structure = {\n",
    "        \"translation\": \"Greek SBLG (SBL Greek New Testament) - Lemmatized\",\n",
    "        \"narrative_units\": narrative_units\n",
    "    }\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(final_json_structure, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"✅ Successfully created '{output_path}'\")\n",
    "\n",
    "\n",
    "# --- 4️⃣ Main Execution Block ---\n",
    "\n",
    "# Step 4a: Pre-processing - Create the structured lemmatized file\n",
    "create_structured_lemmatized_file(OSBORNE_STRUCTURE_PATH, LEMMATIZED_GREEK_PATH, STRUCTURED_LEMMATIZED_PATH)\n",
    "\n",
    "# Step 4b: Load LLM Data for Analysis\n",
    "print(\"\\n\" + \"─\" * 50)\n",
    "print(\"4️⃣  Loading LLM Data and Performing Validation\")\n",
    "print(\"─\" * 50)\n",
    "\n",
    "gem_runs = build_runs_df(load_json(GEMINI_JSON_PATH))\n",
    "groq_runs = build_runs_df(load_json(GROQ_JSON_PATH))\n",
    "\n",
    "gem_runs[\"unit\"] = gem_runs[\"unit\"].map(normalise_uid)\n",
    "groq_runs[\"unit\"] = groq_runs[\"unit\"].map(normalise_uid)\n",
    "\n",
    "# Step 4c: Perform Core Validation Analyses\n",
    "# B.6.1: Intra-model stability (for both models)\n",
    "intra_cos_gemini = mean_pairwise_cos(gem_runs, CATEGORIES)\n",
    "print(f\"Intra-Model Stability (Gemini): Mean Pair-wise Cosine = {intra_cos_gemini:.3f}\")\n",
    "\n",
    "intra_cos_groq = mean_pairwise_cos(groq_runs, CATEGORIES)\n",
    "print(f\"Intra-Model Stability (Groq/Llama): Mean Pair-wise Cosine = {intra_cos_groq:.3f}\")\n",
    "\n",
    "\n",
    "# B.6.1: Cross-model replication (Gemini vs. Groq/Llama)\n",
    "gem_mean = gem_runs.groupby(\"unit\")[CATEGORIES].mean().sort_index()\n",
    "groq_mean = groq_runs.groupby(\"unit\")[CATEGORIES].mean().sort_index()\n",
    "rho, p = spearmanr(gem_mean.to_numpy().flatten(), groq_mean.to_numpy().flatten())\n",
    "print(f\"Cross-Model Replication: Spearman ρ (Gemini vs. Groq/Llama) = {rho:.3f} (p = {p:.4g})\")\n",
    "\n",
    "# B.7: Model-Specific Instability (Groq/Llama)\n",
    "groq_std = groq_runs.groupby(\"unit\")[CATEGORIES].std()\n",
    "verse_range_map = gem_runs.drop_duplicates(subset='unit').set_index('unit')['verse_range']\n",
    "unstable_log = []\n",
    "for unit_id, row in groq_std.iterrows():\n",
    "    if row.max() >= 3.0:\n",
    "        unstable_log.append({\n",
    "            \"Unit (Osborne)\": unit_id,\n",
    "            \"Verse Range\": verse_range_map.get(unit_id, \"N/A\"),\n",
    "            \"Highest-Variance Vector (Groq/Llama)\": row.idxmax(),\n",
    "            \"σ (pp)\": round(row.max(), 2)\n",
    "        })\n",
    "df_unstable = pd.DataFrame(unstable_log).sort_values(by=\"σ (pp)\", ascending=False).reset_index(drop=True)\n",
    "print(\"\\n--- Representative Unstable-Case Log (Groq/Llama Model) ---\")\n",
    "print(df_unstable.to_string())\n",
    "\n",
    "# Step 4d: Morphological Proxy Validation (using the new file)\n",
    "print(\"\\n--- Morphological Proxy Validation ---\")\n",
    "\n",
    "# Define the full, correct set of 15 target lemmas\n",
    "target_lemmas = {\n",
    "    \"προσκυνέω\", \"λατρεύω\", \"δοξάζω\", \"ᾄδω\", \"δόξα\", \"τιμή\", \"κράτος\",\n",
    "    \"δύναμις\", \"εὐλογία\", \"σωτηρία\", \"θυσιαστήριον\", \"ἄξιος\", \"ἀμήν\",\n",
    "    \"ἅγιος\", \"παντοκράτωρ\"\n",
    "}\n",
    "\n",
    "# Load the pre-processed structured data with lemmas\n",
    "structured_lemmatized_data = load_json(STRUCTURED_LEMMATIZED_PATH)\n",
    "lemmatized_texts = {\n",
    "    unit[\"unit_id\"]: unit.get(\"lemmatized_text\", \"\")\n",
    "    for unit in structured_lemmatized_data[\"narrative_units\"]\n",
    "}\n",
    "\n",
    "# Perform the count on the pre-processed lemma strings\n",
    "lemma_counts = {\n",
    "    normalise_uid(uid): sum(1 for lemma in text.split() if lemma in target_lemmas)\n",
    "    for uid, text in lemmatized_texts.items()\n",
    "}\n",
    "\n",
    "# Create DataFrame and merge for correlation analysis\n",
    "lemma_df = pd.DataFrame(lemma_counts.items(), columns=[\"unit\", \"lemma_count\"])\n",
    "merged = gem_mean.reset_index().merge(lemma_df, on=\"unit\", how=\"inner\")\n",
    "\n",
    "print(\"\\n--- Lemma Proxy vs. All Rhetorical Vectors (Pearson r) ---\")\n",
    "lemma_correlations = {}\n",
    "for category in CATEGORIES:\n",
    "    r, p_l = pearsonr(merged[\"lemma_count\"], merged[category])\n",
    "    print(f\"'{category}': r = {r:.3f}  (p = {p_l:.4g})\")\n",
    "    lemma_correlations[category] = {\"r\": r, \"p_value\": p_l}\n",
    "\n",
    "\n",
    "# --- 5️⃣ Save Outputs ---\n",
    "print(\"\\n\" + \"─\" * 50)\n",
    "print(\"5️⃣  Saving Final Outputs\")\n",
    "print(\"─\" * 50)\n",
    "\n",
    "# Create a dictionary of the core validation metrics\n",
    "validation_metrics = {\n",
    "    \"intra_model_stability_gemini\": {\n",
    "        \"model\": \"Gemini\",\n",
    "        \"metric\": \"Mean Pair-wise Cosine Similarity\",\n",
    "        \"value\": intra_cos_gemini\n",
    "    },\n",
    "    \"intra_model_stability_groq\": {\n",
    "        \"model\": \"Groq/Llama\",\n",
    "        \"metric\": \"Mean Pair-wise Cosine Similarity\",\n",
    "        \"value\": intra_cos_groq\n",
    "    },\n",
    "    \"cross_model_replication\": {\n",
    "        \"models\": \"Gemini vs. Groq/Llama\",\n",
    "        \"metric\": \"Spearman Correlation (rho)\",\n",
    "        \"value\": rho,\n",
    "        \"p_value\": p\n",
    "    },\n",
    "    \"morphological_proxy\": {\n",
    "        \"model\": \"Gemini\",\n",
    "        \"metric\": \"Pearson Correlation (r)\",\n",
    "        \"proxy\": \"Cultic Lemma Count vs. All Rhetorical Vectors\",\n",
    "        \"correlations_by_category\": lemma_correlations\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the validation metrics\n",
    "validation_metrics_path = Path(PATH_RESULTS) / 'validation_metrics.json'\n",
    "with open(validation_metrics_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(validation_metrics, f, indent=4)\n",
    "print(f\"✅ Validation metrics saved to '{validation_metrics_path}'\")\n",
    "\n",
    "# Save the unstable case log\n",
    "unstable_log_path = Path(PATH_RESULTS) / 'unstable_case_log.json'\n",
    "df_unstable.to_json(unstable_log_path, orient='records', indent=4)\n",
    "print(f\"✅ Unstable case log saved to '{unstable_log_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdfuEWpk5oPu",
    "outputId": "e96ebf83-8f70-4093-a932-73717e9c9efa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "──────────────────────────────────────────────────\n",
      "Executing Conceptual Integrity Test (Noise Generation & Analysis)\n",
      "Using Noise Level (Standard Deviation): 5.0\n",
      "──────────────────────────────────────────────────\n",
      "Loading original data from '..\\data\\results\\gemini_osborne_greek.json'...\n",
      "Generating noised vectors in memory...\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "Rows are the original classification, columns are the classification after adding noise.\n",
      "Predicted Label (Noised)                  Worship & Praise  Judicial Wrath & Punitive Action  Lament, Persecution & Endurance  Victory, Consolation & New-Creation Hope  Cosmic Warfare & Deception  Prophetic Exhortation & Warning  Theophanic Awe & Terror  Other/Neutral Content\n",
      "True Label (Original)                                                                                                                                                                                                                                                               \n",
      "Worship & Praise                                         5                                 1                                0                                         0                           0                                0                        0                      0\n",
      "Judicial Wrath & Punitive Action                         0                                11                                0                                         0                           0                                0                        0                      0\n",
      "Lament, Persecution & Endurance                          0                                 0                                0                                         0                           0                                1                        0                      0\n",
      "Victory, Consolation & New-Creation Hope                 0                                 0                                0                                         5                           0                                0                        0                      0\n",
      "Cosmic Warfare & Deception                               0                                 0                                0                                         0                           3                                0                        0                      0\n",
      "Prophetic Exhortation & Warning                          0                                 0                                0                                         0                           0                                2                        0                      0\n",
      "Theophanic Awe & Terror                                  0                                 0                                0                                         0                           0                                0                        2                      0\n",
      "Other/Neutral Content                                    0                                 0                                0                                         0                           0                                0                        0                      0\n",
      "\n",
      "--- Analysis of Classification Stability ---\n",
      "Total Units Analyzed: 30\n",
      "Stable Classifications (on diagonal): 28\n",
      "Unstable Classifications (off diagonal): 2\n",
      "Overall Classification Stability: 93.33%\n",
      "\n",
      "--- Details of Classification Changes ---\n",
      "  - unit_013 (RE 10:1-11:13): Changed from 'Lament, Persecution & Endurance' to 'Prophetic Exhortation & Warning'\n",
      "  - unit_019 (RE 15:1-8): Changed from 'Worship & Praise' to 'Judicial Wrath & Punitive Action'\n",
      "\n",
      "✅ Success! All analysis results saved to '..\\data\\results\\conceptual_integrity_metrics.json'\n"
     ]
    }
   ],
   "source": [
    "# @title Stage 3.6 (Combined): Generate Noised Data & Run Conceptual Integrity Test\n",
    "# This single, integrated cell performs the complete conceptual integrity validation.\n",
    "# It first loads the final LLM results, then programmatically adds a configurable\n",
    "# amount of random noise to each rhetorical vector. Finally, it compares the\n",
    "# original classifications with the noised classifications to produce a confusion\n",
    "# matrix and a stability score, saving all metrics to a JSON file.\n",
    "\n",
    "# --- 1️⃣ Setup and Imports ---\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Ensure helper functions can be imported\n",
    "sys.path.append('./')\n",
    "from src.config import *\n",
    "CATEGORIES = ANALYTICAL_CONCEPTS_LIST\n",
    "from src.corpus_parser import load_json\n",
    "\n",
    "# --- 2️⃣ Configuration ---\n",
    "\n",
    "# <<< KEY PARAMETER TO ADJUST >>>\n",
    "# Set the standard deviation of the Gaussian noise to be added to the vectors.\n",
    "# A higher value represents a more aggressive stability test.\n",
    "NOISE_LEVEL_STD_DEV = 5.0\n",
    "\n",
    "# --- File Paths ---\n",
    "PATH_RESULTS = Path(PATH_RESULTS)\n",
    "\n",
    "# Input file for the analysis\n",
    "ORIGINAL_RESULTS_FILE = PATH_RESULTS / \"gemini_osborne_greek.json\"\n",
    "\n",
    "# Output file for the final analysis metrics\n",
    "OUTPUT_METRICS_FILE = PATH_RESULTS / \"conceptual_integrity_metrics.json\"\n",
    "\n",
    "# --- 3️⃣ Helper Function for Noise Generation ---\n",
    "\n",
    "def add_noise_to_vectors(data: dict, noise_level: float) -> dict:\n",
    "    \"\"\"\n",
    "    Iterates through narrative units, adds Gaussian noise to the final\n",
    "    rhetorical vector in memory, and returns the modified data structure.\n",
    "    \"\"\"\n",
    "    noised_data = json.loads(json.dumps(data)) # Deep copy to avoid modifying original\n",
    "\n",
    "    for unit in noised_data.get('narrative_units', []):\n",
    "        original_vector = unit.get('final_rhetorical_vector')\n",
    "\n",
    "        if not isinstance(original_vector, dict):\n",
    "            unit['noised_rhetorical_vector'] = None\n",
    "            continue\n",
    "\n",
    "        noisy_vector = {\n",
    "            category: value + np.random.normal(loc=0.0, scale=noise_level)\n",
    "            for category, value in original_vector.items()\n",
    "        }\n",
    "        noisy_vector = {k: max(0, v) for k, v in noisy_vector.items()}\n",
    "\n",
    "        total_sum = sum(noisy_vector.values())\n",
    "        if total_sum > 0:\n",
    "            noisy_vector = {k: (v / total_sum) * 100 for k, v in noisy_vector.items()}\n",
    "        else:\n",
    "            num_categories = len(original_vector)\n",
    "            noisy_vector = {k: 100.0 / num_categories for k in original_vector.keys()}\n",
    "\n",
    "        current_sum = sum(noisy_vector.values())\n",
    "        diff = 100.0 - current_sum\n",
    "        if diff != 0:\n",
    "            max_key = max(noisy_vector, key=noisy_vector.get)\n",
    "            noisy_vector[max_key] += diff\n",
    "\n",
    "        unit['noised_rhetorical_vector'] = noisy_vector\n",
    "\n",
    "    return noised_data\n",
    "\n",
    "# --- 4️⃣ Main Execution Block ---\n",
    "\n",
    "print(\"─\" * 50)\n",
    "print(\"Executing Conceptual Integrity Test (Noise Generation & Analysis)\")\n",
    "print(f\"Using Noise Level (Standard Deviation): {NOISE_LEVEL_STD_DEV}\")\n",
    "print(\"─\" * 50)\n",
    "\n",
    "try:\n",
    "    # Step 4a: Load the original data\n",
    "    print(f\"Loading original data from '{ORIGINAL_RESULTS_FILE}'...\")\n",
    "    original_data = load_json(ORIGINAL_RESULTS_FILE)\n",
    "    if not original_data:\n",
    "        raise FileNotFoundError(\"The original results file could not be loaded or is empty.\")\n",
    "\n",
    "    # Step 4b: Generate the noised data in memory\n",
    "    print(\"Generating noised vectors in memory...\")\n",
    "    noised_data = add_noise_to_vectors(original_data, NOISE_LEVEL_STD_DEV)\n",
    "\n",
    "    # Step 4c: Extract the \"winning\" category and track changes\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    classification_changes = []\n",
    "\n",
    "    original_units = {unit['unit_id']: unit for unit in original_data['narrative_units']}\n",
    "    noised_units = {unit['unit_id']: unit for unit in noised_data['narrative_units']}\n",
    "\n",
    "    for unit_id in sorted(original_units.keys()):\n",
    "        if unit_id in noised_units:\n",
    "            original_vector = original_units[unit_id].get('final_rhetorical_vector')\n",
    "            noised_vector = noised_units[unit_id].get('noised_rhetorical_vector')\n",
    "\n",
    "            if original_vector and noised_vector:\n",
    "                original_winner = max(original_vector, key=original_vector.get)\n",
    "                noised_winner = max(noised_vector, key=noised_vector.get)\n",
    "\n",
    "                true_labels.append(original_winner)\n",
    "                predicted_labels.append(noised_winner)\n",
    "\n",
    "                if original_winner != noised_winner:\n",
    "                    classification_changes.append({\n",
    "                        \"unit_id\": unit_id,\n",
    "                        \"verse_range\": original_units[unit_id].get('verse_range'),\n",
    "                        \"original_classification\": original_winner,\n",
    "                        \"noised_classification\": noised_winner\n",
    "                    })\n",
    "\n",
    "    if not true_labels:\n",
    "        raise ValueError(\"No valid vectors found to compare.\")\n",
    "\n",
    "    # Step 4d: Compute and display the confusion matrix as a table\n",
    "    cm_df = pd.crosstab(\n",
    "        pd.Series(true_labels, name='True Label (Original)'),\n",
    "        pd.Series(predicted_labels, name='Predicted Label (Noised)'),\n",
    "        rownames=['True Label (Original)'],\n",
    "        colnames=['Predicted Label (Noised)'],\n",
    "        dropna=False\n",
    "    ).reindex(index=CATEGORIES, columns=CATEGORIES, fill_value=0)\n",
    "\n",
    "    print(\"\\n--- Confusion Matrix ---\")\n",
    "    print(\"Rows are the original classification, columns are the classification after adding noise.\")\n",
    "    print(cm_df.to_string())\n",
    "\n",
    "    # Step 4e: Calculate and display stability metrics\n",
    "    correct_predictions = np.trace(cm_df.values)\n",
    "    total_predictions = len(true_labels)\n",
    "    stability_score = (correct_predictions / total_predictions) * 100 if total_predictions > 0 else 0\n",
    "\n",
    "    print(\"\\n--- Analysis of Classification Stability ---\")\n",
    "    print(f\"Total Units Analyzed: {total_predictions}\")\n",
    "    print(f\"Stable Classifications (on diagonal): {correct_predictions}\")\n",
    "    print(f\"Unstable Classifications (off diagonal): {total_predictions - correct_predictions}\")\n",
    "    print(f\"Overall Classification Stability: {stability_score:.2f}%\")\n",
    "\n",
    "    if classification_changes:\n",
    "        print(\"\\n--- Details of Classification Changes ---\")\n",
    "        for change in classification_changes:\n",
    "            print(f\"  - {change['unit_id']} ({change['verse_range']}): Changed from '{change['original_classification']}' to '{change['noised_classification']}'\")\n",
    "    else:\n",
    "        print(\"\\n--- No classification changes were observed. ---\")\n",
    "\n",
    "    # Step 4f: Save all results to a single JSON file\n",
    "    output_results = {\n",
    "        \"analysis_summary\": {\n",
    "            \"description\": \"Compares the primary rhetorical classification of units before and after adding Gaussian noise to test conceptual integrity.\",\n",
    "            \"noise_level_std_dev\": NOISE_LEVEL_STD_DEV,\n",
    "            \"total_units_analyzed\": total_predictions,\n",
    "            \"stable_classifications\": int(correct_predictions),\n",
    "            \"unstable_classifications\": int(total_predictions - correct_predictions),\n",
    "            \"overall_stability_percent\": stability_score\n",
    "        },\n",
    "        \"classification_changes\": classification_changes,\n",
    "        \"confusion_matrix\": cm_df.to_dict('index')\n",
    "    }\n",
    "\n",
    "    with open(OUTPUT_METRICS_FILE, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output_results, f, indent=4)\n",
    "\n",
    "    print(f\"\\n✅ Success! All analysis results saved to '{OUTPUT_METRICS_FILE}'\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n❌ ERROR: {e}. Please ensure the input file exists in '{PATH_RESULTS}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ An unexpected error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
